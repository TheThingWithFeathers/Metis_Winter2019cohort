{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import dateutil.relativedelta as ddelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up parameters for the code\n",
    "start_date = dt.date(2013,1,1) #start of the time range for weather scraping\n",
    "end_date = dt.date(2018,12,31)  #end of the time range for weather scraping\n",
    "weather_dates = []              #list of year-month strings to input into weather website to scrape\n",
    "my_data = []                    #final output of all scraped daily weather data, to be pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete Selenium setup\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the list of months to be scraped\n",
    "curr_date = start_date\n",
    "\n",
    "while curr_date < end_date:\n",
    "    weather_dates.append(str(curr_date.year)+'-'+str(curr_date.month))\n",
    "    curr_date = curr_date + ddelta.relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start weather scraping - open the site and set station to Seattle Area\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(\"https://nowdata.rcc-acis.org/sew/\")\n",
    "time.sleep(1)\n",
    "\n",
    "#Select the Seattle Area option under \"Location\" menu\n",
    "element = driver.find_element_by_name('station')\n",
    "all_options = element.find_elements_by_tag_name(\"option\")\n",
    "all_options[2].click()\n",
    "\n",
    "#although \"daily data\" is the default option, add code to select it just to be safe\n",
    "product_choice = driver.find_element_by_name('product_select')\n",
    "product_choice.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape through the data for each month\n",
    "\n",
    "for scrape_month in weather_dates:\n",
    "    \n",
    "    #Select the right year and month\n",
    "    date_field = driver.find_element_by_id(\"tDatepicker\")\n",
    "    date_field.click()\n",
    "    date_field.clear()\n",
    "    date_field.send_keys(scrape_month)\n",
    "    \n",
    "    #hit Go to load the data!\n",
    "    go_button = driver.find_element_by_id(\"go\")\n",
    "    go_button.send_keys(Keys.ENTER)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    #read in the resulting table\n",
    "    my_results = driver.find_element_by_id(\"results_area\")\n",
    "    my_table = my_results.find_element_by_tag_name(\"tbody\")\n",
    "    my_table_rows = my_table.find_elements_by_tag_name(\"tr\")\n",
    "    \n",
    "    for row in my_table_rows:\n",
    "        new_row = []\n",
    "        my_table_cols = row.find_elements_by_tag_name(\"td\")\n",
    "        \n",
    "        for col in my_table_cols:\n",
    "            new_row.append(col.text)\n",
    "        my_data.append(new_row)\n",
    "        \n",
    "    #exit out of this view to load the next date\n",
    "    close_button = my_results.find_element_by_xpath('/html/body/div[4]/div[1]/button[3]').click()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now pickle that thing in case of apocalypse!\n",
    "with open('weather2.pickle', 'wb') as to_write:\n",
    "    pickle.dump(my_data, to_write)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
